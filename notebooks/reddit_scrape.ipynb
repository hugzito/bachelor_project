{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "Tutorial for reddit scraping: https://www.geeksforgeeks.org/scraping-reddit-using-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from praw.models import MoreComments\n",
    "# from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# ids for scraping (from christians setup)\n",
    "client_id = 'Ut5UgaAMOEWBELtYRWnw0g'\n",
    "client_secret = '5xGs1w6mav5Ke685afpG28Q8nfusmg'\n",
    "user_agent = 'polarity search'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping\n",
    "\n",
    "First we initialize a read-only instance. A read-only instance can only scrape publicly available information and cannot upvote or otherwise interact like users can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Version 7.6.1 of praw is outdated. Version 7.7.0 was released Saturday February 25, 2023.\n"
     ]
    }
   ],
   "source": [
    "# Read-only instance\n",
    "reddit_read_only = praw.Reddit(client_id=client_id,         # your client id\n",
    "                               client_secret=client_secret,      # your client secret\n",
    "                               user_agent=user_agent)        # your user agent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting comments on a specific post\n",
    "\n",
    "This code scrapes over the comments of a specified post. It looks only at the top-level comments (none of the replies to comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_post(url, n=100):\n",
    "    '''given a url:\n",
    "     - scrapes n number of top-level comments\n",
    "     - comment author (username) and comment body ()\n",
    "     - outputs a pandas dataframe'''\n",
    "\n",
    "    # Creating a submission object\n",
    "    submission = reddit_read_only.submission(url=url)\n",
    "    \n",
    "    # should get all top level comments on the post\n",
    "    #if all_comments==True:\n",
    "    #    submission.comments.replace_more(limit=None)\n",
    "\n",
    "    post_authors = []\n",
    "    post_comments = []\n",
    "\n",
    "    # specifying how many times we should \"load more comments\"\n",
    "    limit = round(n/20) # n/20 ensures we hit load more enough times to scrape the number of comments we want \n",
    "    submission.comments.replace_more(limit=limit, threshold=0)\n",
    "\n",
    "    count = 0 # tracking how many comments have been scraped\n",
    "    for comment in submission.comments: # iterates only over top level comments\n",
    "        # stops counting when n amount of comments have been scraped\n",
    "        if count == n:\n",
    "            break\n",
    "\n",
    "        if type(comment) == MoreComments:\n",
    "            continue\n",
    "\n",
    "        post_authors.append(comment.author)\n",
    "        post_comments.append(comment.body)\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    post_dict = {'author': post_authors, 'comment': post_comments}\n",
    "    post_df = pd.DataFrame(post_dict)\n",
    "    \n",
    "    return post_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of how scraping a post works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping a post without much content - takes <1 second\n",
    "# there are 12 top level comments\n",
    "df = scrape_post(\"https://www.reddit.com/r/MaraudersGame/comments/ylxsq4/marauders_be_like/\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping a decently sized post (function default scrapes 100 comments) - takes ~10 seconds\n",
    "df = scrape_post(\"https://www.reddit.com/r/politics/comments/1092xhl/the_american_public_no_longer_believes_the/\")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scraping 200 comments from a decently sized post (post has 3.8k comments) - takes ~15 seconds\n",
    "df = scrape_post(\"https://www.reddit.com/r/politics/comments/1092xhl/the_american_public_no_longer_believes_the/\", n=200)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aidan: idk what below line was so i just commented it out\n",
    "# praw.models.reddit.submission.Submission?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting top month posts on specified subreddit\n",
    "This code grabs the top 100 posts of the past month and saves various information on them into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_top_month(subreddit, ppsr=100):\n",
    "    # specifying subreddit\n",
    "    subreddit = reddit_read_only.subreddit(subreddit)\n",
    "\n",
    "    # Specifying to look at top posts of the current month\n",
    "    posts = subreddit.top(\"month\", limit=ppsr)\n",
    "\n",
    "    # Initializing dictionary to save post data to\n",
    "    posts_dict = {\"Title\": [], \"Post Text\": [],\n",
    "                  \"ID\": [], \"Score\": [],\n",
    "                  \"Total Comments\": [], \"Post URL\": [], 'Post_author' : []\n",
    "                  }\n",
    "\n",
    "    # Loop for saving post details\n",
    "    for post in posts:\n",
    "        # print(post)\n",
    "        # Title of each post\n",
    "        posts_dict[\"Title\"].append(post.title)\n",
    "\n",
    "        # Text inside a post\n",
    "        posts_dict[\"Post Text\"].append(post.selftext)\n",
    "\n",
    "        # Unique ID of each post\n",
    "        posts_dict[\"ID\"].append(post.id)\n",
    "\n",
    "        # The score of a post\n",
    "        posts_dict[\"Score\"].append(post.score)\n",
    "\n",
    "        # Total number of comments inside the post\n",
    "        posts_dict[\"Total Comments\"].append(post.num_comments)\n",
    "\n",
    "        # Author of the post\n",
    "        posts_dict['Post_author'].append(post.author)\n",
    "\n",
    "        # URL of each post\n",
    "        # print('https://www.reddit.com'+f'{post.permalink}')\n",
    "        posts_dict[\"Post URL\"].append('https://www.reddit.com'+f'{post.permalink}')\n",
    "        \n",
    "    return posts_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of how scraping top month posts works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\AppData\\Local\\Temp\\ipykernel_1700\\1251007598.py:6: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"month\", limit=ppsr)\n"
     ]
    }
   ],
   "source": [
    "dict_ = scrape_top_month('politics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden to propose 25% billionaire tax\n",
      "\n",
      "11mgaw2\n",
      "98322\n",
      "6016\n",
      "https://www.reddit.com/r/politics/comments/11mgaw2/biden_to_propose_25_billionaire_tax/\n",
      "100\n",
      "bhodrolok\n"
     ]
    }
   ],
   "source": [
    "# post samples\n",
    "print(dict_['Title'][0])\n",
    "print(dict_['Post Text'][0])\n",
    "print(dict_['ID'][0])\n",
    "print(dict_['Score'][0])\n",
    "print(dict_['Total Comments'][0])\n",
    "print(dict_['Post URL'][0])\n",
    "print(len(dict_['Title']))\n",
    "print(dict_['Post_author'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\AppData\\Local\\Temp\\ipykernel_1700\\1251007598.py:6: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"month\", limit=ppsr)\n"
     ]
    }
   ],
   "source": [
    "dict_ = scrape_top_month('politics', ppsr=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden to propose 25% billionaire tax\n",
      "\n",
      "11mgaw2\n",
      "98313\n",
      "6016\n",
      "https://www.reddit.com/r/politics/comments/11mgaw2/biden_to_propose_25_billionaire_tax/\n",
      "150\n",
      "bhodrolok\n"
     ]
    }
   ],
   "source": [
    "# post samples\n",
    "print(dict_['Title'][0])\n",
    "print(dict_['Post Text'][0])\n",
    "print(dict_['ID'][0])\n",
    "print(dict_['Score'][0])\n",
    "print(dict_['Total Comments'][0])\n",
    "print(dict_['Post URL'][0])\n",
    "print(len(dict_['Title']))\n",
    "print(dict_['Post_author'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting comments on top monthly posts on multiple subreddits\n",
    "\n",
    "Data we are keeping and why:\n",
    " - post_title: to embed and become node values of our users\n",
    " - post_url: in case we ever want to visit the post for any inspection reasons\n",
    " - comment_author: to keep track of who left the comment\n",
    " - comment_text: to analyse the sentiment of the comment towards the post\n",
    " - post_author: to track who made the post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_multiple_save(subreddits, ppsr=100, n=100, save=False, destination=''):\n",
    "    '''scrapes and saves subreddit comments to csv files\n",
    "     - subreddits: list of subreddit name strings, fx Politics\n",
    "     - ppsr: number of posts per subbreddit to scrape\n",
    "     - n: number of comments per post to scrape'''\n",
    "    \n",
    "    if save==False:\n",
    "        print('WARNING: save=True has not been specified!')\n",
    "\n",
    "    print(f'Scraping {ppsr} posts per subreddit and {n} comments per post')\n",
    "    \n",
    "    # looping through subreddits\n",
    "    for subreddit in subreddits:\n",
    "        print(f'Scraping r/{subreddit}...')\n",
    "        \n",
    "        # initialize dictionary for saving all comments and post info\n",
    "        sub_dict = {'post_title': [],\n",
    "                    # 'post_text': [],\n",
    "                    # 'post_id': [],\n",
    "                    # 'post_score': [],\n",
    "                    # 'post_total_comments': [],\n",
    "                    'post_url': [],\n",
    "                    'comment_author': [],\n",
    "                    'comment_text': [], \n",
    "                    'post_author' : []}\n",
    "        \n",
    "        posts_dict = scrape_top_month(subreddit, ppsr) # getting top of the month post info\n",
    "        \n",
    "        # looping through posts\n",
    "        for idx, url in tqdm(enumerate(posts_dict['Post URL']),):\n",
    "            \n",
    "            # df for comments on the post\n",
    "            comment_df = scrape_post(url, n=n)\n",
    "            \n",
    "            # looping through comments on post and appending all comment info to sub_dict\n",
    "            for row_idx, row in comment_df.iterrows():\n",
    "                sub_dict['post_title'].append(posts_dict['Title'][idx])\n",
    "                # sub_dict['post_text'].append(posts_dict['Post Text'][idx])\n",
    "                # sub_dict['post_id'].append(posts_dict['ID'][idx])\n",
    "                # sub_dict['post_score'].append(posts_dict['Score'][idx])\n",
    "                # sub_dict['post_total_comments'].append(posts_dict['Total Comments'][idx])\n",
    "                sub_dict['post_url'].append(posts_dict['Post URL'][idx])\n",
    "                sub_dict['comment_author'].append(row['author'])\n",
    "                sub_dict['comment_text'].append(row['comment'])\n",
    "                sub_dict['post_author'].append(posts_dict['Post_author'][idx])\n",
    "            \n",
    "        # changing sub_dict to pandas dataframe\n",
    "        global sub_df\n",
    "        sub_df = pd.DataFrame.from_dict(sub_dict)\n",
    "\n",
    "        # saving to csv\n",
    "        if save==True:\n",
    "            sub_df.to_csv(f'{destination}{subreddit}.csv', index=False)\n",
    "        \n",
    "    print('Done!')\n",
    "\n",
    "    if save==True:\n",
    "        return None\n",
    "    else:\n",
    "        return sub_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use function\n",
    "\n",
    "Below line shows how to scrape r/politics, scraping 200 posts and 100 comments from each post.\n",
    "\n",
    "It won't save the dataframe unless save=True is specified, so that it can be tested without overwriting anything.\n",
    "\n",
    "It takes ~ 30-40 minutes to run as it's scraping 200*100 = 20,000 comments. It won't end up actually being 20,000 comments however, probably because 200 posts down there will be less than 100 top-level comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: save=True has not been specified!\n",
      "Scraping 200 posts per subreddit and 100 comments per post\n",
      "Scraping r/politics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aidan\\AppData\\Local\\Temp\\ipykernel_1700\\1251007598.py:6: DeprecationWarning: Positional arguments for 'BaseListingMixin.top' will no longer be supported in PRAW 8.\n",
      "Call this function with 'time_filter' as a keyword argument.\n",
      "  posts = subreddit.top(\"month\", limit=ppsr)\n",
      "200it [34:22, 10.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# takes ~ 40 minutes to run (it's scraping 200*100 = 20,000 comments - though it wont be that many)\n",
    "df_test = scrape_multiple_save(['politics'], ppsr=200, n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19340, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_url</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>post_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Biden to propose 25% billionaire tax</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/11m...</td>\n",
       "      <td>AutoModerator</td>\n",
       "      <td>\\nAs a reminder, this subreddit [is for civil ...</td>\n",
       "      <td>bhodrolok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Biden to propose 25% billionaire tax</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/11m...</td>\n",
       "      <td>rounder55</td>\n",
       "      <td>But that'll impact the 7th generation of my li...</td>\n",
       "      <td>bhodrolok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biden to propose 25% billionaire tax</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/11m...</td>\n",
       "      <td>LudovicoSpecs</td>\n",
       "      <td>Now we're talking.\\n\\nStop going after the peo...</td>\n",
       "      <td>bhodrolok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biden to propose 25% billionaire tax</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/11m...</td>\n",
       "      <td>amorousambrosia</td>\n",
       "      <td>You know who's gonna be the most pissed off ab...</td>\n",
       "      <td>bhodrolok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Biden to propose 25% billionaire tax</td>\n",
       "      <td>https://www.reddit.com/r/politics/comments/11m...</td>\n",
       "      <td>atxlrj</td>\n",
       "      <td>Here in Texas, they have a Vehicle Asset Test ...</td>\n",
       "      <td>bhodrolok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             post_title  \\\n",
       "0  Biden to propose 25% billionaire tax   \n",
       "1  Biden to propose 25% billionaire tax   \n",
       "2  Biden to propose 25% billionaire tax   \n",
       "3  Biden to propose 25% billionaire tax   \n",
       "4  Biden to propose 25% billionaire tax   \n",
       "\n",
       "                                            post_url   comment_author  \\\n",
       "0  https://www.reddit.com/r/politics/comments/11m...    AutoModerator   \n",
       "1  https://www.reddit.com/r/politics/comments/11m...        rounder55   \n",
       "2  https://www.reddit.com/r/politics/comments/11m...    LudovicoSpecs   \n",
       "3  https://www.reddit.com/r/politics/comments/11m...  amorousambrosia   \n",
       "4  https://www.reddit.com/r/politics/comments/11m...           atxlrj   \n",
       "\n",
       "                                        comment_text post_author  \n",
       "0  \\nAs a reminder, this subreddit [is for civil ...   bhodrolok  \n",
       "1  But that'll impact the 7th generation of my li...   bhodrolok  \n",
       "2  Now we're talking.\\n\\nStop going after the peo...   bhodrolok  \n",
       "3  You know who's gonna be the most pissed off ab...   bhodrolok  \n",
       "4  Here in Texas, they have a Vehicle Asset Test ...   bhodrolok  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_test.shape)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "testy = df_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_title', 'post_url', 'comment_author', 'comment_text',\n",
       "       'post_author'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden to propose 25% billionaire tax\n"
     ]
    }
   ],
   "source": [
    "print(testy['post_title'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.reddit.com/r/politics/comments/11mgaw2/biden_to_propose_25_billionaire_tax/\n"
     ]
    }
   ],
   "source": [
    "print(testy['post_url'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoModerator\n"
     ]
    }
   ],
   "source": [
    "print(testy['comment_author'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "As a reminder, this subreddit [is for civil discussion.](/r/politics/wiki/index#wiki_be_civil)\n",
      "\n",
      "In general, be courteous to others. Debate/discuss/argue the merits of ideas, don't attack people. Personal insults, shill or troll accusations, hate speech, any suggestion or support of harm, violence, or death, and other rule violations can result in a permanent ban. \n",
      "\n",
      "If you see comments in violation of our rules, please report them.\n",
      "\n",
      " For those who have questions regarding any media outlets being posted on this subreddit, please click [here](https://www.reddit.com/r/politics/wiki/approveddomainslist) to review our details as to our approved domains list and outlet criteria.\n",
      " \n",
      "\n",
      "***\n",
      "\n",
      "\n",
      "*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/politics) if you have any questions or concerns.*\n"
     ]
    }
   ],
   "source": [
    "print(testy['comment_text'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bhodrolok\n"
     ]
    }
   ],
   "source": [
    "print(testy['post_author'][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running scrapes - ONLY RUN IF WILLING TO LEAVE RUNNING FOR HOURS\n",
    "\n",
    "Make sure to specify destination folder before running. Example destination: destination='../data/28feb/scrapes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape_multiple_save(['politics'], ppsr=200, n=100, save=True, destination='../data/15march/scrapes/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
